{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/biomedical/01_Drug_Discovery_Pipeline.ipynb)\n",
        "\n",
        "# Drug Discovery Pipeline - Vector Similarity Search\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates a **complete drug discovery pipeline** using Semantica that focuses on **vector similarity search** and **interaction prediction**. The pipeline ingests drug and protein data, extracts compound and target entities, builds a drug-target knowledge graph, and performs similarity search to predict drug-target interactions.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Vector-Focused Approach**: Emphasizes embeddings and vector similarity search for drug-target interaction prediction\n",
        "- **Compound-Target Extraction**: Extracts drug compounds, proteins, and targets from biomedical literature\n",
        "- **Similarity Search**: Uses vector embeddings to find similar compounds and predict interactions\n",
        "- **Knowledge Graph Construction**: Builds structured drug-target relationship graphs\n",
        "- **Interaction Prediction**: Predicts potential drug-target interactions using similarity metrics\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- How to ingest biomedical data (drug databases, protein data, literature)\n",
        "- How to extract compound and target entities from unstructured text\n",
        "- How to generate embeddings for drugs and proteins\n",
        "- How to perform similarity search to find similar compounds\n",
        "- How to build drug-target knowledge graphs\n",
        "- How to predict drug-target interactions using vector similarity\n",
        "\n",
        "### Pipeline Architecture\n",
        "\n",
        "1. **Phase 0**: Setup & Configuration\n",
        "2. **Phase 1**: Biomedical Data Ingestion\n",
        "3. **Phase 2**: Document Parsing & Processing\n",
        "4. **Phase 3**: Entity Extraction (Drugs, Proteins, Targets)\n",
        "5. **Phase 4**: Embedding Generation\n",
        "6. **Phase 5**: Vector Store Population\n",
        "7. **Phase 6**: Similarity Search & Interaction Prediction\n",
        "8. **Phase 7**: Knowledge Graph Construction\n",
        "9. **Phase 8**: Visualization & Export\n",
        "\n",
        "---\n",
        "\n",
        "## Installation\n",
        "\n",
        "Install Semantica and required dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Semantica and required dependencies\n",
        "%pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu beautifulsoup4 groq sentence-transformers scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 0: Setup & Configuration\n",
        "\n",
        "Configure Semantica for drug discovery with focus on vector similarity search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Set API keys\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\", \"your-groq-api-key-here\")\n",
        "\n",
        "print(\"Environment configured.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.core import Semantica, ConfigManager\n",
        "from semantica.vector_store import VectorStore\n",
        "from semantica.embeddings import EmbeddingGenerator\n",
        "from semantica.semantic_extract import NamedEntityRecognizer, RelationExtractor\n",
        "\n",
        "# Configure for drug discovery with vector similarity focus\n",
        "config_dict = {\n",
        "    \"project_name\": \"Drug_Discovery_Pipeline\",\n",
        "    \"embedding\": {\n",
        "        \"provider\": \"sentence_transformers\",\n",
        "        \"model\": \"all-MiniLM-L6-v2\"  # 384-dimensional embeddings\n",
        "    },\n",
        "    \"extraction\": {\n",
        "        \"provider\": \"groq\",\n",
        "        \"model\": \"llama-3.1-8b-instant\",\n",
        "        \"temperature\": 0.0\n",
        "    },\n",
        "    \"vector_store\": {\n",
        "        \"provider\": \"faiss\",\n",
        "        \"dimension\": 384\n",
        "    },\n",
        "    \"knowledge_graph\": {\n",
        "        \"backend\": \"networkx\",\n",
        "        \"merge_entities\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "config = ConfigManager().load_from_dict(config_dict)\n",
        "core = Semantica(config=config)\n",
        "vector_store = VectorStore(backend=\"faiss\", dimension=384)\n",
        "\n",
        "print(\"Semantica configured for drug discovery pipeline.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 1: Real Data Ingestion (PubMed RSS Feed)\n",
        "\n",
        "Ingest biomedical data from PubMed RSS feeds using FeedIngestor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FeedIngestor, FileIngestor\n",
        "import os\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Option 1: Ingest from PubMed RSS feed (real data source)\n",
        "# PubMed RSS feed for drug discovery research\n",
        "pubmed_rss_url = \"https://pubmed.ncbi.nlm.nih.gov/rss/search/1?term=drug+discovery&limit=10&sort=pub_date&fc=article_type\"\n",
        "\n",
        "try:\n",
        "    feed_ingestor = FeedIngestor()\n",
        "    # Ingest from PubMed RSS feed\n",
        "    feed_documents = feed_ingestor.ingest(pubmed_rss_url, method=\"rss\")\n",
        "    print(f\"Ingested {len(feed_documents)} documents from PubMed RSS feed\")\n",
        "    documents = feed_documents\n",
        "except Exception as e:\n",
        "    print(f\"RSS feed ingestion failed (using sample data): {e}\")\n",
        "    # Fallback: Sample drug and protein data\n",
        "    sample_drug_data = \"\"\"\n",
        "    Aspirin (acetylsalicylic acid) is a medication used to reduce pain, fever, or inflammation. \n",
        "    It targets cyclooxygenase enzymes COX-1 and COX-2. Aspirin is commonly used for cardiovascular protection.\n",
        "    Ibuprofen is a nonsteroidal anti-inflammatory drug (NSAID) that targets COX-1 and COX-2 enzymes.\n",
        "    Metformin is an antidiabetic medication that targets AMP-activated protein kinase (AMPK).\n",
        "    Insulin targets the insulin receptor (INSR) to regulate glucose metabolism.\n",
        "    Warfarin is an anticoagulant that targets vitamin K epoxide reductase complex subunit 1 (VKORC1).\n",
        "    Atorvastatin is a statin medication that targets HMG-CoA reductase.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Save sample data\n",
        "    with open(\"data/sample_drugs.txt\", \"w\") as f:\n",
        "        f.write(sample_drug_data)\n",
        "    \n",
        "    # Ingest from file\n",
        "    file_ingestor = FileIngestor()\n",
        "    documents = file_ingestor.ingest(\"data/sample_drugs.txt\")\n",
        "    print(f\"Ingested {len(documents)} documents from sample data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "---\n",
        "\n",
        "## Phase 2: Text Normalization & Cleaning\n",
        "\n",
        "Normalize and clean ingested text data using the normalize module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.normalize import TextNormalizer\n",
        "\n",
        "# Normalize and clean text data\n",
        "normalizer = TextNormalizer()\n",
        "\n",
        "# Normalize all documents\n",
        "normalized_documents = []\n",
        "for doc in documents:\n",
        "    normalized_text = normalizer.normalize(\n",
        "        doc.content if hasattr(doc, 'content') else str(doc),\n",
        "        clean_html=True,\n",
        "        normalize_entities=True,\n",
        "        remove_extra_whitespace=True,\n",
        "        lowercase=False  # Preserve drug names (case-sensitive)\n",
        "    )\n",
        "    normalized_documents.append(normalized_text)\n",
        "\n",
        "print(f\"Normalized {len(normalized_documents)} documents\")\n",
        "print(f\"Sample normalized text (first 200 chars): {normalized_documents[0][:200] if normalized_documents else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 3: Advanced Chunking (Entity-Aware)\n",
        "\n",
        "Use entity-aware chunking to preserve drug/protein entity boundaries for GraphRAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.split import TextSplitter, EntityAwareChunker\n",
        "\n",
        "# Use entity-aware chunking to preserve drug/protein entity boundaries\n",
        "# This is crucial for GraphRAG workflows to maintain entity context\n",
        "splitter = TextSplitter(\n",
        "    method=\"entity_aware\",\n",
        "    ner_method=\"llm\",  # Use LLM for better entity recognition\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Alternative: Use EntityAwareChunker directly\n",
        "entity_chunker = EntityAwareChunker(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    ner_method=\"llm\",\n",
        "    preserve_entities=True\n",
        ")\n",
        "\n",
        "# Chunk normalized documents\n",
        "chunked_documents = []\n",
        "for doc_text in normalized_documents:\n",
        "    chunks = splitter.split(doc_text)\n",
        "    chunked_documents.extend(chunks)\n",
        "\n",
        "print(f\"Created {len(chunked_documents)} chunks using entity-aware chunking\")\n",
        "print(f\"Sample chunk (first 300 chars): {chunked_documents[0].content[:300] if chunked_documents else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 4: Entity Extraction & Knowledge Graph Construction\n",
        "\n",
        "Extract drug and protein entities, then build knowledge graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert chunks to document format for entity extraction\n",
        "# Chunks from TextSplitter have content attribute\n",
        "chunk_docs = []\n",
        "for chunk in chunked_documents:\n",
        "    # Create a simple document-like object\n",
        "    doc_content = chunk.content if hasattr(chunk, 'content') else str(chunk)\n",
        "    chunk_docs.append(doc_content)\n",
        "\n",
        "# Build knowledge base with entity extraction\n",
        "result = core.build_knowledge_base(\n",
        "    sources=chunk_docs,\n",
        "    custom_entity_types=[\"Drug\", \"Protein\", \"Target\", \"Compound\", \"Enzyme\", \"Receptor\"],\n",
        "    embeddings=True,\n",
        "    graph=True\n",
        ")\n",
        "\n",
        "# Extract entities\n",
        "entities = result[\"entities\"]\n",
        "drugs = [e for e in entities if e.get(\"type\") == \"Drug\" or \"drug\" in e.get(\"type\", \"\").lower()]\n",
        "proteins = [e for e in entities if e.get(\"type\") == \"Protein\" or \"protein\" in e.get(\"type\", \"\").lower()]\n",
        "\n",
        "print(f\"Extracted {len(drugs)} drugs and {len(proteins)} proteins\")\n",
        "print(f\"Sample drugs: {[d.get('text', '')[:30] for d in drugs[:3]]}\")\n",
        "print(f\"Sample proteins: {[p.get('text', '')[:30] for p in proteins[:3]]}\")\n",
        "\n",
        "# Get knowledge graph\n",
        "kg = result[\"knowledge_graph\"]\n",
        "print(f\"Knowledge graph contains {len(kg.get('entities', []))} entities and {len(kg.get('relationships', []))} relationships\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 5: Vector Store Population & Embedding Generation\n",
        "\n",
        "Generate embeddings and populate vector store for similarity search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 4-5: Vector Store & Similarity Search\n",
        "\n",
        "Generate embeddings and populate vector store for similarity search.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 6: GraphRAG - Hybrid Vector + Graph Retrieval\n",
        "\n",
        "Use AgentContext for GraphRAG to combine vector similarity search with knowledge graph traversal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.context import AgentContext\n",
        "\n",
        "# Initialize GraphRAG context with vector store and knowledge graph\n",
        "context = AgentContext(vector_store=vector_store, knowledge_graph=kg)\n",
        "\n",
        "# Example GraphRAG query: Find drugs and their targets\n",
        "query = \"What drugs target COX enzymes?\"\n",
        "print(f\"Query: {query}\\n\")\n",
        "\n",
        "# Retrieve using GraphRAG (hybrid vector + graph retrieval)\n",
        "results = context.retrieve(\n",
        "    query,\n",
        "    max_results=10,\n",
        "    use_graph=True,  # Enable graph traversal\n",
        "    expand_graph=True,  # Expand graph relationships\n",
        "    include_entities=True,  # Include related entities\n",
        "    include_relationships=True  # Include relationships\n",
        ")\n",
        "\n",
        "print(f\"GraphRAG retrieved {len(results)} results:\\n\")\n",
        "for i, result in enumerate(results[:5], 1):\n",
        "    print(f\"{i}. Score: {result.get('score', 0):.3f}\")\n",
        "    print(f\"   Content: {result.get('content', '')[:200]}...\")\n",
        "    if result.get('related_entities'):\n",
        "        print(f\"   Related entities: {len(result['related_entities'])}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 7: Similarity Search & Interaction Prediction\n",
        "\n",
        "Use vector similarity to find similar drugs and predict interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.embeddings import EmbeddingGenerator\n",
        "\n",
        "# Generate embeddings for drugs and proteins\n",
        "embedding_gen = EmbeddingGenerator(provider=\"sentence_transformers\", model=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create drug embeddings\n",
        "drug_texts = [f\"{d.get('text', '')} {d.get('description', '')}\" for d in drugs]\n",
        "drug_embeddings = embedding_gen.generate_embeddings(drug_texts)\n",
        "\n",
        "# Store in vector store\n",
        "drug_ids = vector_store.store_vectors(\n",
        "    vectors=drug_embeddings,\n",
        "    metadata=[{\"type\": \"drug\", \"name\": d.get(\"text\", \"\")} for d in drugs]\n",
        ")\n",
        "\n",
        "print(f\"Stored {len(drug_ids)} drug embeddings in vector store\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 8: Knowledge Graph Visualization\n",
        "\n",
        "Visualize drug-target knowledge graph and relationships.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 6: Similarity Search & Interaction Prediction\n",
        "\n",
        "Use vector similarity to find similar drugs and predict interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Find drugs similar to Aspirin\n",
        "query_drug = \"Aspirin\"\n",
        "query_embedding = embedding_gen.generate_embeddings([query_drug])[0]\n",
        "\n",
        "# Search for similar drugs\n",
        "similar_drugs = vector_store.search_vectors(query_embedding, k=5)\n",
        "\n",
        "print(f\"Drugs similar to '{query_drug}':\")\n",
        "for i, result in enumerate(similar_drugs, 1):\n",
        "    print(f\"{i}. {result['metadata'].get('name', 'Unknown')} (similarity: {result['score']:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 7-8: Knowledge Graph & Visualization\n",
        "\n",
        "Build drug-target knowledge graph and visualize relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.visualization import KGVisualizer\n",
        "\n",
        "# Get knowledge graph from result\n",
        "kg = result[\"knowledge_graph\"]\n",
        "\n",
        "# Visualize drug-target relationships\n",
        "visualizer = KGVisualizer()\n",
        "visualizer.visualize(\n",
        "    kg,\n",
        "    output_path=\"drug_target_kg.html\",\n",
        "    layout=\"spring\",\n",
        "    node_size=20\n",
        ")\n",
        "\n",
        "print(\"Knowledge graph visualization saved to drug_target_kg.html\")\n",
        "print(f\"Graph contains {len(kg.get('entities', []))} entities and {len(kg.get('relationships', []))} relationships\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
