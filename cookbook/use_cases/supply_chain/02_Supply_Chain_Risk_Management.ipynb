{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/supply_chain/02_Supply_Chain_Risk_Management.ipynb)\n",
        "\n",
        "# Supply Chain Risk Management - Dependency Analysis & Reasoning\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates **supply chain risk management** using Semantica with focus on **dependency analysis**, **risk pattern detection**, and **external feed correlation**. The pipeline detects risks in the supply chain by analyzing dependencies and external feeds using reasoning and analytics.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Dependency Analysis**: Analyzes supply chain dependencies using graph reasoning\n",
        "- **Risk Pattern Detection**: Detects risk patterns in the supply chain\n",
        "- **External Feed Correlation**: Correlates external feeds with supply chain data\n",
        "- **Reasoning**: Emphasizes reasoning and analytics for risk detection\n",
        "- **Risk Mitigation**: Identifies mitigation strategies through graph analysis\n",
        "\n",
        "### Pipeline Architecture\n",
        "\n",
        "1. **Phase 0**: Setup & Configuration\n",
        "2. **Phase 1**: Supply Chain & External Feed Ingestion\n",
        "3. **Phase 2**: Entity Extraction (Dependency, Risk, Disruption, Impact, Mitigation)\n",
        "4. **Phase 3**: Supply Chain Knowledge Graph Construction\n",
        "5. **Phase 4**: Dependency Analysis\n",
        "6. **Phase 5**: Risk Pattern Detection\n",
        "7. **Phase 6**: External Feed Correlation\n",
        "8. **Phase 7**: Visualization & Risk Reporting\n",
        "\n",
        "---\n",
        "\n",
        "## Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU semantica networkx matplotlib plotly pandas groq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 0: Setup & Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from semantica.core import Semantica, ConfigManager\n",
        "from semantica.reasoning import GraphReasoner\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\", \"your-key\")\n",
        "\n",
        "config_dict = {\n",
        "    \"project_name\": \"Supply_Chain_Risk_Management\",\n",
        "    \"extraction\": {\"provider\": \"groq\", \"model\": \"llama-3.1-8b-instant\"},\n",
        "    \"knowledge_graph\": {\"backend\": \"networkx\"}\n",
        "}\n",
        "\n",
        "config = ConfigManager().load_from_dict(config_dict)\n",
        "core = Semantica(config=config)\n",
        "print(\"Configured for supply chain risk management with reasoning focus\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 1: Real Data Ingestion (Supply Chain RSS Feeds)\n",
        "\n",
        "Ingest supply chain risk data from RSS feeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.ingest import FeedIngestor, FileIngestor\n",
        "from semantica.normalize import TextNormalizer\n",
        "from semantica.conflicts import ConflictDetector\n",
        "import os\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Ingest from supply chain RSS feeds\n",
        "supply_feeds = [\n",
        "    # Add supply chain news RSS feeds here\n",
        "]\n",
        "\n",
        "documents = []\n",
        "for feed_url in supply_feeds:\n",
        "    try:\n",
        "        feed_ingestor = FeedIngestor()\n",
        "        feed_documents = feed_ingestor.ingest(feed_url, method=\"rss\")\n",
        "        documents.extend(feed_documents)\n",
        "    except Exception as e:\n",
        "        print(f\"Feed ingestion failed: {e}\")\n",
        "\n",
        "# Fallback: Sample data\n",
        "if not documents:\n",
        "    risk_data = \"\"\"\n",
        "    Supplier A depends on raw materials from Region R1 (high risk region).\n",
        "    Disruption in Region R1 impacts Supplier A, causing supply chain risk.\n",
        "    External feed: Weather alert in Region R1 may disrupt logistics.\n",
        "    Risk mitigation: Identify alternative suppliers in Region R2.\n",
        "    \"\"\"\n",
        "    with open(\"data/supply_chain_risks.txt\", \"w\") as f:\n",
        "        f.write(risk_data)\n",
        "    documents = FileIngestor().ingest(\"data/supply_chain_risks.txt\")\n",
        "    print(f\"Ingested {len(documents)} documents from sample data\")\n",
        "\n",
        "# Normalize risk data\n",
        "normalizer = TextNormalizer()\n",
        "normalized_documents = []\n",
        "for doc in documents:\n",
        "    normalized_text = normalizer.normalize(\n",
        "        doc.content if hasattr(doc, 'content') else str(doc),\n",
        "        clean_html=True,\n",
        "        normalize_entities=True,\n",
        "        remove_extra_whitespace=True\n",
        "    )\n",
        "    normalized_documents.append(normalized_text)\n",
        "\n",
        "print(f\"Normalized {len(normalized_documents)} documents\")\n",
        "\n",
        "# Build supply chain risk knowledge graph\n",
        "result = core.build_knowledge_base(\n",
        "    sources=normalized_documents,\n",
        "    custom_entity_types=[\"Dependency\", \"Risk\", \"Disruption\", \"Impact\", \"Mitigation\"],\n",
        "    graph=True\n",
        ")\n",
        "\n",
        "kg = result[\"knowledge_graph\"]\n",
        "entities = result[\"entities\"]\n",
        "\n",
        "# Detect conflicts in risk data\n",
        "detector = ConflictDetector()\n",
        "conflicts = detector.detect_conflicts(entities, kg.get(\"relationships\", []))\n",
        "\n",
        "print(f\"Built risk management KG with {len(kg.get('entities', []))} entities\")\n",
        "print(f\"Detected {len(conflicts)} conflicts in risk data\")\n",
        "if conflicts:\n",
        "    resolved = detector.resolve_conflicts(conflicts, strategy=\"highest_confidence\")\n",
        "    print(f\"Resolved {len(resolved)} conflicts\")\n",
        "print(\"Focus: Dependency analysis, risk pattern detection, external feed correlation, reasoning\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze dependencies using reasoning\n",
        "reasoner = GraphReasoner(kg)\n",
        "dependencies = reasoner.find_patterns(pattern_type=\"dependency\")\n",
        "risk_patterns = reasoner.find_patterns(pattern_type=\"risk\")\n",
        "\n",
        "# Identify high-risk dependencies\n",
        "high_risk = [e for e in kg.get(\"entities\", []) \n",
        "             if e.get(\"type\") == \"Risk\" and \n",
        "             \"high\" in str(e.get(\"text\", \"\")).lower()]\n",
        "\n",
        "print(f\"Dependency analysis: {len(dependencies)} dependencies identified\")\n",
        "print(f\"Risk pattern detection: {len(risk_patterns)} risk patterns found\")\n",
        "print(f\"High-risk items: {len(high_risk)} high-risk dependencies flagged\")\n",
        "print(\"This cookbook emphasizes reasoning and analytics for risk management\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 7: Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semantica.visualization import KGVisualizer\n",
        "\n",
        "visualizer = KGVisualizer()\n",
        "visualizer.visualize(kg, output_path=\"supply_chain_risk_kg.html\")\n",
        "\n",
        "print(\"Supply chain risk management analysis complete\")\n",
        "print(\"Emphasizes: Dependency analysis, risk pattern detection, external feed correlation, reasoning\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
